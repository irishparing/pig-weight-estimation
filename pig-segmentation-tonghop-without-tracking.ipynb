{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a736d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095b0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Roboflow inference client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://outline.roboflow.com\",\n",
    "    api_key=\"7Oj4lP3s5DlHk2Syfc6G\"\n",
    ")\n",
    "MODEL_ID = \"data_tonghop/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a5aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output setup\n",
    "input_folder = \"./batch1\"  # Replace with your video folder path\n",
    "output_base_dir = \"./batch1/output_segmented\"\n",
    "if not os.path.exists(output_base_dir):\n",
    "    os.makedirs(output_base_dir)\n",
    "\n",
    "# Supported video extensions\n",
    "video_extensions = [\"*.mp4\", \"*.avi\", \"*.mov\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f8576b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing depth_rgb_recording(1): 100%|██████████| 557/557 [08:55<00:00,  1.04frame/s]\n",
      "Processing depth_rgb_recording(3): 100%|██████████| 575/575 [08:12<00:00,  1.17frame/s]\n",
      "Processing depth_rgb_recording(4): 100%|██████████| 1062/1062 [18:06<00:00,  1.02s/frame]\n",
      "Processing depth_rgb_recording(5): 100%|██████████| 462/462 [09:37<00:00,  1.25s/frame]\n",
      "Processing depth_rgb_recording(6): 100%|██████████| 1102/1102 [23:25<00:00,  1.28s/frame]\n",
      "Processing depth_rgb_recording(8): 100%|██████████| 667/667 [13:59<00:00,  1.26s/frame]\n"
     ]
    }
   ],
   "source": [
    "# Process each video\n",
    "for ext in video_extensions:\n",
    "    for video_path in glob(os.path.join(input_folder, ext)):\n",
    "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        output_dir = os.path.join(output_base_dir, video_name)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Open video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # Verify video dimensions\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        if width != 1280 or height != 480:\n",
    "            print(f\"Skipping {video_name}: Dimensions must be 1280x480, got {width}x{height}\")\n",
    "            cap.release()\n",
    "            continue\n",
    "\n",
    "        # Get total frame count for progress bar\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_count = 0\n",
    "        temp_rgb_path = f\"temp_rgb_{video_name}.jpg\"\n",
    "\n",
    "        # Process frames with progress bar\n",
    "        with tqdm(total=total_frames, desc=f\"Processing {video_name}\", unit=\"frame\") as pbar:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "                # Split frame into depth (left) and RGB (right)\n",
    "                depth_frame = frame[:, :640, :]  # Left 640x480\n",
    "                rgb_frame = frame[:, 640:, :]    # Right 640x480\n",
    "\n",
    "                # Save RGB frame temporarily for inference\n",
    "                cv2.imwrite(temp_rgb_path, rgb_frame)\n",
    "\n",
    "                # Run inference on RGB frame\n",
    "                try:\n",
    "                    predictions = CLIENT.infer(temp_rgb_path, model_id=MODEL_ID)\n",
    "                except Exception as e:\n",
    "                    print(f\"Inference failed for {video_name}, frame {frame_count}: {e}\")\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Process predictions to extract pig masks\n",
    "                current_masks = []\n",
    "                for pred in predictions.get(\"predictions\", []):\n",
    "                    if pred.get(\"class\") == \"pig\":  # Adjust if class name differs\n",
    "                        mask = np.zeros((480, 640), dtype=np.uint8)\n",
    "                        if \"points\" in pred:  # If model returns polygon\n",
    "                            points = np.array([[p[\"x\"], p[\"y\"]] for p in pred[\"points\"]], dtype=np.int32)\n",
    "                            cv2.fillPoly(mask, [points], 255)\n",
    "                        elif \"mask\" in pred:  # If model returns bitmap mask\n",
    "                            mask = np.array(pred[\"mask\"], dtype=np.uint8)\n",
    "                            if mask.shape != (480, 640):\n",
    "                                mask = cv2.resize(mask, (640, 480), interpolation=cv2.INTER_NEAREST)\n",
    "                        current_masks.append(mask)\n",
    "\n",
    "                # Apply masks to segment RGB and depth frames\n",
    "                for i, mask in enumerate(current_masks):\n",
    "                    # Ensure mask is binary\n",
    "                    mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "                    # Segment RGB frame\n",
    "                    segmented_rgb = cv2.bitwise_and(rgb_frame, rgb_frame, mask=mask)\n",
    "\n",
    "                    # Segment depth frame\n",
    "                    if depth_frame.shape[2] == 3:  # If depth is RGB-encoded\n",
    "                        segmented_depth = cv2.bitwise_and(depth_frame, depth_frame, mask=mask)\n",
    "                    else:  # If depth is grayscale\n",
    "                        segmented_depth = cv2.bitwise_and(depth_frame, depth_frame, mask=mask)\n",
    "                        segmented_depth = cv2.cvtColor(segmented_depth, cv2.COLOR_GRAY2BGR)  # Convert for PNG\n",
    "\n",
    "                    # Save every 5 frames\n",
    "                    if frame_count % 5 == 0:\n",
    "                        cv2.imwrite(os.path.join(output_dir, f\"frame_{frame_count}_rgb_crop_{i}.png\"), segmented_rgb)\n",
    "                        cv2.imwrite(os.path.join(output_dir, f\"frame_{frame_count}_depth_crop_{i}.png\"), segmented_depth)\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Clean up\n",
    "        cap.release()\n",
    "        if os.path.exists(temp_rgb_path):\n",
    "            os.remove(temp_rgb_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
