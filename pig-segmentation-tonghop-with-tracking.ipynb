{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec5c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbed855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Roboflow inference client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://outline.roboflow.com\",\n",
    "    api_key=\"6db3vtCdSMg4O2FRfZZn\"\n",
    ")\n",
    "MODEL_ID = \"data_tonghop/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae5c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output setup\n",
    "input_folder = \"./batch3\"  # Replace with your video folder path\n",
    "output_base_dir = \"./batch3/output_segmented\"\n",
    "if not os.path.exists(output_base_dir):\n",
    "    os.makedirs(output_base_dir)\n",
    "\n",
    "# Supported video extensions\n",
    "video_extensions = [\"*.mp4\", \"*.avi\", \"*.mov\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78faaae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU calculation for tracking\n",
    "def compute_iou(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c244020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing depth_rgb_recording(5): 100%|██████████| 5035/5035 [1:43:45<00:00,  1.24s/frame]\n"
     ]
    }
   ],
   "source": [
    "for ext in video_extensions:\n",
    "    for video_path in glob(os.path.join(input_folder, ext)):\n",
    "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        output_dir = os.path.join(output_base_dir, video_name)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Open video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # Verify video dimensions\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        if width != 1280 or height != 480:\n",
    "            print(f\"Skipping {video_name}: Dimensions must be 1280x480, got {width}x{height}\")\n",
    "            cap.release()\n",
    "            continue\n",
    "\n",
    "        # Get total frame count for progress bar\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        frame_count = 0\n",
    "        temp_rgb_path = f\"temp_rgb_{video_name}.jpg\"\n",
    "        tracks = []  # List of (track_id, mask) for tracking\n",
    "        next_track_id = 0\n",
    "\n",
    "        # Initialize progress bar\n",
    "        with tqdm(total=total_frames, desc=f\"Processing {video_name}\", unit=\"frame\") as pbar:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "                # Split frame into depth (left) and RGB (right)\n",
    "                depth_frame = frame[:, :640, :]  # Left 640x480\n",
    "                rgb_frame = frame[:, 640:, :]    # Right 640x480\n",
    "\n",
    "                # Save RGB frame temporarily for inference\n",
    "                cv2.imwrite(temp_rgb_path, rgb_frame)\n",
    "\n",
    "                # Run inference on RGB frame\n",
    "                try:\n",
    "                    predictions = CLIENT.infer(temp_rgb_path, model_id=MODEL_ID)\n",
    "                except Exception as e:\n",
    "                    print(f\"Inference failed for {video_name}, frame {frame_count}: {e}\")\n",
    "                    pbar.update(1)  # Update progress bar even on failure\n",
    "                    continue\n",
    "\n",
    "                # Process predictions to extract pig masks\n",
    "                current_masks = []\n",
    "                for pred in predictions.get(\"predictions\", []):\n",
    "                    if pred.get(\"class\") == \"pig\":  # Adjust if class name differs\n",
    "                        mask = np.zeros((480, 640), dtype=np.uint8)\n",
    "                        if \"points\" in pred:  # If model returns polygon\n",
    "                            points = np.array([[p[\"x\"], p[\"y\"]] for p in pred[\"points\"]], dtype=np.int32)\n",
    "                            cv2.fillPoly(mask, [points], 255)\n",
    "                        elif \"mask\" in pred:  # If model returns bitmap mask\n",
    "                            mask = np.array(pred[\"mask\"], dtype=np.uint8)\n",
    "                            if mask.shape != (480, 640):\n",
    "                                mask = cv2.resize(mask, (640, 480), interpolation=cv2.INTER_NEAREST)\n",
    "                        current_masks.append(mask)\n",
    "\n",
    "                # Track pigs using IoU\n",
    "                new_tracks = []\n",
    "                matched = set()\n",
    "                for mask in current_masks:\n",
    "                    best_iou = 0\n",
    "                    best_track_id = None\n",
    "                    for track_id, prev_mask in tracks:\n",
    "                        iou = compute_iou(mask, prev_mask)\n",
    "                        if iou > best_iou and iou > 0.5:  # IoU threshold\n",
    "                            best_iou = iou\n",
    "                            best_track_id = track_id\n",
    "                    if best_track_id is not None and best_track_id not in matched:\n",
    "                        new_tracks.append((best_track_id, mask))\n",
    "                        matched.add(best_track_id)\n",
    "                    else:\n",
    "                        new_tracks.append((next_track_id, mask))\n",
    "                        next_track_id += 1\n",
    "                tracks = new_tracks  # Update tracks\n",
    "\n",
    "                # Apply masks to segment RGB and depth frames\n",
    "                for track_id, mask in tracks:\n",
    "                    # Ensure mask is binary\n",
    "                    mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "                    # Segment RGB frame\n",
    "                    segmented_rgb = cv2.bitwise_and(rgb_frame, rgb_frame, mask=mask)\n",
    "\n",
    "                    # Segment depth frame\n",
    "                    if depth_frame.shape[2] == 3:  # If depth is RGB-encoded\n",
    "                        segmented_depth = cv2.bitwise_and(depth_frame, depth_frame, mask=mask)\n",
    "                    else:  # If depth is grayscale\n",
    "                        segmented_depth = cv2.bitwise_and(depth_frame, depth_frame, mask=mask)\n",
    "                        segmented_depth = cv2.cvtColor(segmented_depth, cv2.COLOR_GRAY2BGR)  # Convert for PNG\n",
    "\n",
    "                    # Save every 5 frames\n",
    "                    if frame_count % 5 == 0:\n",
    "                        pig_dir = os.path.join(output_dir, f\"pig_{track_id}\")\n",
    "                        if not os.path.exists(pig_dir):\n",
    "                            os.makedirs(pig_dir)\n",
    "                        cv2.imwrite(os.path.join(pig_dir, f\"frame_{frame_count}_rgb_crop_{track_id}.png\"), segmented_rgb)\n",
    "                        cv2.imwrite(os.path.join(pig_dir, f\"frame_{frame_count}_depth_crop_{track_id}.png\"), segmented_depth)\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Clean up\n",
    "        cap.release()\n",
    "        if os.path.exists(temp_rgb_path):\n",
    "            os.remove(temp_rgb_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
