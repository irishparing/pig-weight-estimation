{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6f9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "import os\n",
    "import tempfile\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6043499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Roboflow inference client\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://outline.roboflow.com\",\n",
    "    api_key=\"6db3vtCdSMg4O2FRfZZn\"\n",
    ")\n",
    "\n",
    "MODEL_ID = \"data_tonghop/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40af16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "input_folder = \".\\\\Sample_P-Weigh\"\n",
    "done_folder = os.path.join(input_folder, \"Done\")\n",
    "output_folder = os.path.join(input_folder, \"outputs_pig_id\")\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(done_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Padding for bounding boxes\n",
    "padding = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b42af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specific colors (BGR format)\n",
    "COLORS = [\n",
    "    (0, 255, 0),    # Green\n",
    "    (255, 0, 255),  # Pink\n",
    "    (0, 255, 255),  # Yellow\n",
    "    (255, 0, 0),    # Blue\n",
    "    (0, 0, 255),    # Red\n",
    "    (0, 165, 255)   # Orange\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3224da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to match new bounding boxes to existing tracks\n",
    "def match_bboxes(new_bboxes, tracked_pigs, max_distance=100):\n",
    "    new_tracked_pigs = []\n",
    "    used_indices = set()\n",
    "\n",
    "    # Calculate centers of new bounding boxes\n",
    "    new_centers = [((bbox['x1'] + bbox['x2']) / 2, (bbox['y1'] + bbox['y2']) / 2) for bbox in new_bboxes]\n",
    "\n",
    "    # Match each tracked pig to the closest new bounding box\n",
    "    for pig in tracked_pigs:\n",
    "        if not new_centers:\n",
    "            continue\n",
    "        last_center = pig['last_center']\n",
    "        distances = [distance.euclidean(last_center, center) for center in new_centers]\n",
    "        min_distance_idx = np.argmin(distances)\n",
    "        if distances[min_distance_idx] < max_distance and min_distance_idx not in used_indices:\n",
    "            # Update pig with new bounding box\n",
    "            pig['bbox'] = new_bboxes[min_distance_idx]\n",
    "            pig['last_center'] = new_centers[min_distance_idx]\n",
    "            new_tracked_pigs.append(pig)\n",
    "            used_indices.add(min_distance_idx)\n",
    "\n",
    "    # Add new pigs for unmatched bounding boxes\n",
    "    for idx, bbox in enumerate(new_bboxes):\n",
    "        if idx not in used_indices:\n",
    "            new_id = len(new_tracked_pigs) + 1\n",
    "            color_idx = (new_id - 1) % len(COLORS)\n",
    "            new_tracked_pigs.append({\n",
    "                'id': new_id,\n",
    "                'name': f'Pig {new_id}',\n",
    "                'color': COLORS[color_idx],\n",
    "                'bbox': bbox,\n",
    "                'last_center': new_centers[idx]\n",
    "            })\n",
    "\n",
    "    return new_tracked_pigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a676e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each video in the folder\n",
    "for video_file in os.listdir(input_folder):\n",
    "    if not video_file.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    video_path = os.path.join(input_folder, video_file)\n",
    "    video_name = os.path.splitext(video_file)[0]\n",
    "\n",
    "    # Create output subfolder for this video\n",
    "    video_output_folder = os.path.join(output_folder, video_name)\n",
    "    os.makedirs(video_output_folder, exist_ok=True)\n",
    "\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Calculate frame interval (every half second or 15 frames)\n",
    "    frame_interval = min(int(fps * 0.5), 15)  # Half a second or 15 frames, whichever is smaller\n",
    "\n",
    "    # Output video path\n",
    "    output_video_path = os.path.join(video_output_folder, f\"{video_name}_processed.mp4\")\n",
    "\n",
    "    # Video writer to save output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width // 2, frame_height))\n",
    "\n",
    "    frame_count = 0\n",
    "    tracked_pigs = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extract only RGB side (right half of the frame)\n",
    "        rgb_frame = frame[:, frame_width // 2:]\n",
    "\n",
    "        # Process bounding boxes every frame_interval\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Save the RGB frame to a temporary file\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as temp_file:\n",
    "                temp_image_path = temp_file.name\n",
    "                cv2.imwrite(temp_image_path, rgb_frame)\n",
    "\n",
    "            try:\n",
    "                # Perform inference via Roboflow API\n",
    "                response = CLIENT.infer(temp_image_path, model_id=MODEL_ID)\n",
    "                \n",
    "                new_bboxes = []\n",
    "                for prediction in response['predictions']:\n",
    "                    x = int(prediction['x'])\n",
    "                    y = int(prediction['y'])\n",
    "                    width = int(prediction['width'])\n",
    "                    height = int(prediction['height'])\n",
    "\n",
    "                    # Calculate bounding box coordinates\n",
    "                    x1 = max(x - width // 2 - padding, 0)\n",
    "                    y1 = max(y - height // 2 - padding, 0)\n",
    "                    x2 = min(x + width // 2 + padding, rgb_frame.shape[1] - 1)\n",
    "                    y2 = min(y + height // 2 + padding, rgb_frame.shape[0] - 1)\n",
    "\n",
    "                    new_bboxes.append({\n",
    "                        'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2\n",
    "                    })\n",
    "\n",
    "                # Match new bounding boxes to tracked pigs\n",
    "                tracked_pigs = match_bboxes(new_bboxes, tracked_pigs)\n",
    "\n",
    "            finally:\n",
    "                # Clean up the temporary file\n",
    "                if os.path.exists(temp_image_path):\n",
    "                    os.remove(temp_image_path)\n",
    "\n",
    "        # Draw bounding boxes and names on current frame\n",
    "        for pig in tracked_pigs:\n",
    "            bbox = pig['bbox']\n",
    "            color = pig['color']\n",
    "            name = pig['name']\n",
    "\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(rgb_frame, \n",
    "                         (bbox['x1'], bbox['y1']), \n",
    "                         (bbox['x2'], bbox['y2']), \n",
    "                         color, \n",
    "                         2)\n",
    "\n",
    "            # Draw name above the bounding box\n",
    "            cv2.putText(rgb_frame, name, \n",
    "                       (bbox['x1'], bbox['y1'] - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.6, \n",
    "                       color, \n",
    "                       2)\n",
    "\n",
    "        # Write the RGB frame to the output video\n",
    "        out.write(rgb_frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release resources for this video\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Move processed video to \"Done\" folder\n",
    "    os.rename(video_path, os.path.join(done_folder, video_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363d7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Outputs saved in .\\Sample_P-Weigh\\outputs_pig_id\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing complete. Outputs saved in {output_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
